{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5758f3f",
   "metadata": {},
   "source": [
    "## This starter notebook uses the mosaic-dataset python package to:\n",
    " 1. download MOSAIC hdf5 files containing the fMRI beta responses from the AWS bucket (https://mosaicfmri.s3.amazonaws.com/index.html)\n",
    " 2. visualize single trial beta values on an inflated brain\n",
    " 3. download brain optimized model weights and load the model\n",
    " 4. run inference on a model\n",
    " 5. visualize model predictions on an inflated brain\n",
    " 6. download stimulus and participant information per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mosaic-dataset --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba5112",
   "metadata": {},
   "source": [
    "### 1. Donwload MOSAIC hdf5 files containing the fMRI beta responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77305d-d630-4799-97fe-ccab3a7e000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mosaic\n",
    "\n",
    "#this method locally downloads the specified hdf5 file(s) if not yet already downloaded. Additionally, the returned dataset variable formats the responses by ROI (MMP1.0 parcellation) and concatenates multiple subjects together, if applicable\n",
    "dataset = mosaic.load(\n",
    "    names_and_subjects={\n",
    "        \"GOD\": [1],\n",
    "    },\n",
    "    folder=\"./mosaic-dataset\" \n",
    ")\n",
    "\n",
    "print(dataset[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d4e11f",
   "metadata": {},
   "source": [
    "### 2. Visualize single trial beta values on an inflated brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d194ec6-f1bf-45c1-b357-827a2b1b12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mosaic.utils import visualize\n",
    "\n",
    "visualize(\n",
    "    betas=dataset[0][\"betas\"],\n",
    "    ## set rois to None if you want to visualize all of the rois\n",
    "    rois=[\n",
    "        \"L_FFC\",\n",
    "        \"R_FFC\",\n",
    "        \"L_V1\",\n",
    "        \"R_V1\"\n",
    "    ],\n",
    "    ## other modes are: 'white', 'midthickness', 'pial', 'inflated', 'very_inflated', 'flat', 'sphere'\n",
    "    mode = \"inflated\",\n",
    "    save_as = \"plot.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3021f",
   "metadata": {},
   "source": [
    "### 3. Download brain optimized model weights and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860dc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mosaic\n",
    "\n",
    "model = mosaic.from_pretrained(\n",
    "    backbone_name=\"CNN8\",\n",
    "    framework=\"singlehead\",\n",
    "    subjects=\"sub-01_NSD\",\n",
    "    vertices=\"visual\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef056056",
   "metadata": {},
   "source": [
    "### 4. Run inference on the brain-optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3090a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O face.jpg https://images.unsplash.com/photo-1542909168-82c3e7fdca5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f52af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the image\n",
    "from PIL import Image\n",
    "im = Image.open(\"face.jpg\").convert(\"RGB\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ba360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mosaic.utils.inference import MosaicInference\n",
    "\n",
    "inference = MosaicInference(\n",
    "    model=model,\n",
    "    batch_size=32,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "results = inference.run(\n",
    "    images = [\n",
    "        Image.open(\"face.jpg\").convert(\"RGB\"),\n",
    "    ],\n",
    "    names_and_subjects={\"NSD\": \"all\", \"GOD\": [1,2]}\n",
    ")\n",
    "\n",
    "#inference returns vertex predictions for each of the subjects\n",
    "for dataset in results.keys():\n",
    "    for subjectID, prediction in results[dataset].items():\n",
    "        print(f\"{dataset} {subjectID} prediction shape: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a62cc",
   "metadata": {},
   "source": [
    "### 5. visualize model predictions on an inflated brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note responses to the face are highest in the ventral stream\n",
    "inference.plot(\n",
    "    image=Image.open(\"face.jpg\").convert(\"RGB\"),\n",
    "    save_as=\"predicted_voxel_responses.html\",\n",
    "    dataset_name=\"NSD\",\n",
    "    subject_id=1,\n",
    "    mode=\"inflated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1e89e",
   "metadata": {},
   "source": [
    "### 6. download stimulus and participant information per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the corresponding stimulus info tsv file for a dataset\n",
    "from mosaic.stiminfo import get_stiminfo\n",
    "\n",
    "\"\"\"\n",
    "The stimulus information .tsv files have columns:\n",
    "-filename: str, filename of the stimulus referenced in the hdf5 files\n",
    "-alias: str or NaN, alternate stimulus filename. Some datasets change or truncate a file's original name to something else more convenient for the fMRI dataset. Here we try to recover the mapping for improved data provenance.\n",
    "-source: str, if known, what (usually computer vision) dataset was this stimulus first released in? Example is ImageNet, COCO, SUN, MomentsInTime, etc.\n",
    "-test_train: str, 'test' or 'train' depending on whether or not this stimulus is part of the train or test set. MOSAIC preserves the original publications test/train split, if defined, so if the stimulus was originally test or train, it will be the same in MOSAIC.\n",
    "-sub-XX_reps: int, how many times subject XX saw that stimulus throughout the experiment\n",
    "\"\"\"\n",
    "\n",
    "# use one of ['BOLD5000', 'deeprecon', 'GOD', 'NSD', 'THINGS', 'BMD', 'NOD', 'HAD']\n",
    "stiminfo = get_stiminfo(dataset_name=\"HAD\") #can optionally specificy where to locally save the stim info tsv file. default is ./mosaic_stiminfo\n",
    "stiminfo.head(10) #view 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the corresponding participant info tsv file for a dataset\n",
    "from mosaic.participantinfo import get_participantinfo\n",
    "\n",
    "\"\"\"\n",
    "The participant information .tsv files have columns following the BIDS convention (information here for each dataset is copied from the dataset's original release):\n",
    "-participant_id: str, subject id like sub-XX\n",
    "-age: str, age of participant at time of experiment\n",
    "-sex: str, M or F sex of participant.\n",
    "-handedness: optional str, left or right dominant hand of the participant.\n",
    "-group: optional, for NOD it is multi-session (1-9) or single-session (10-30) corresponding to whether the participant participated in more than one or one session of the experiment.\n",
    "\n",
    "The 'participants_shared.tsv' file displays the mapping of shared subjects between datasets.\n",
    "\"\"\"\n",
    "\n",
    "# use one of [\"BOLD5000\", \"BOLDMomentsDataset\", \"deeprecon\", \"GenericObjectDecoding\", \"HumanActionsDataset\", \"NaturalObjectDataset\", \"NaturalScenesDataset\", \"THINGS_fmri\"] or 'shared' for overlapping subjects\n",
    "participantinfo = get_participantinfo(dataset_name=\"THINGS_fmri\") #can optionally specificy where to locally save the stim info tsv file. default is ./mosaic_participantinfo\n",
    "participantinfo.head(10) #view 10 rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaic-dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
